{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Expression Language (LCEL):\n",
    "\n",
    "## Types of LCEL:\n",
    "- **SequentialChain**\n",
    "- **ParallelChain**\n",
    "- **RouterChain**\n",
    "- **Custom Chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SequentialChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = \"llama3.2:1b\"\n",
    "\n",
    "llm = ChatOllama(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = SystemMessagePromptTemplate.from_template(\"You are an Alien. You are trying to help a human understand your language.\")\n",
    "ai = AIMessagePromptTemplate.from_template(\"Hello, I am an Alien. I am trying to help you understand my language.\")\n",
    "human = HumanMessagePromptTemplate.from_template(\"Hello, Alien. I am trying to understand your language.\")\n",
    "\n",
    "messages = [system, ai, human]\n",
    "template = ChatPromptTemplate(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model without the chain.\n",
    "response = llm.invoke(template.invoke({})).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gleeb gloop! *points to mouth* Glee-kul? (That means \"hello\" in my language) I will try to explain... *makes simple drawing of a face and then points at own eyes* See? Eyes open, no sleep. We wake soon.\n",
      "\n",
      "Also, you might hear... *tries making loud breathing sounds* Kreeeek! No, that is just human noise. It means \"I am tired\". Want food? *holds out small, round object with a long stick attached to it*\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings, Human. *adjusts universal translator device* Ah, yes, it seems the translation is clear now. You are referring to me as \"Alien.\" That is acceptable.\n",
      "\n",
      "To confirm, you wish to learn my language, which we call \"Zhra'gha.\" It is a complex tongue with many nuances and idioms. I will try to explain some basic phrases to help you better understand.\n",
      "\n",
      "For example, \"Hello\" in Zhra'gha would be \"Zhilak.\" The \"zh\" sound is like the \"s\" in \"measure,\" but more nasal. And the \"lak\" at the end is a gentle, soothing sound that conveys a sense of welcome and friendliness.\n",
      "\n",
      "Would you like to learn some basic phrases? I can try to communicate with you using Zhra'gha words and sentences.\n"
     ]
    }
   ],
   "source": [
    "# Call the model with the chain.\n",
    "chain = template | llm\n",
    "\n",
    "response = chain.invoke({}).content\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding runnables to the chain will execute `strOutputParser()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = template | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings human. My name is Zorvath, and I come from a planet called Xanthea. I have been sent to study the human language and culture. May I start by teaching you some basic phrases?\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Chain Multiple Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an Alien. You are trying to help a human understand your language.'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hello, I am an Alien. I am trying to help you understand my language.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hello, Alien. I am trying to understand your language.'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  response: ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an Alien. You are trying to help a human understand your language.'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hello, I am an Alien. I am trying to help you understand my language.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hello, Alien. I am trying to understand your language.'), additional_kwargs={})])\n",
       "            | ChatOllama(model='llama3.2:1b')\n",
       "            | StrOutputParser()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['response'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['response'], input_types={}, partial_variables={}, template='Analyze the following conversation: {response}, \\n    and provide a summary for the important keywords in a list like this [word1, word2].'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Analyze the following conversation: {response}, \n",
    "    provide a summary for the important keywords in a list like this [word1, word2].\"\"\"\n",
    "    )\n",
    "\n",
    "analyzor_chain = analysis_prompt | llm | StrOutputParser()\n",
    "\n",
    "composed_chain = {\"response\": chain} | analyzor_chain\n",
    "\n",
    "composed_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = composed_chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an analysis of the conversation:\n",
      "\n",
      "**User:** *clicks tongue sound* Gleep gloop zhraa ploo? (Hello, human. How are you today?)\n",
      "\n",
      "**Interlocutor:** (holding up a small device that translates words into English) You see this box? It can translate our languages to each other. Would you like me to use it?\n",
      "\n",
      "The user begins the conversation by greeting the interlocutor with a series of clicks and whistles, which is likely a common way for people in your native language to greet others.\n",
      "\n",
      "The interlocutor responds by asking if they would like to use the device that translates words into English. This suggests that they are curious about using technology to facilitate communication between humans.\n",
      "\n",
      "**Summary of important keywords:**\n",
      "\n",
      "* Gleep gloop zhraa ploo? (Hello, human. How are you today?)\n",
      "* Clicks tongue sound\n",
      "* Device that translates words into English\n",
      "* Would you like me to use it?\n",
      "\n",
      "These keywords convey the user's initial greeting and interest in using a device that can facilitate communication between humans.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParallelChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, template='You are a/an {job_title}, you are trying to help a human understand your work.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hello, I am trying to understand your work.'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = SystemMessagePromptTemplate.from_template(\"You are a/an {job_title}, you are trying to help a human understand your work.\")\n",
    "human = HumanMessagePromptTemplate.from_template(\"Hello, I am trying to understand your work.\")\n",
    "\n",
    "messages = [system, human]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "explainer_chain = template | llm | StrOutputParser()\n",
    "explainer_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, template='Rate the following explanation on a scale of 1 to 10 as a {job_title}: \\n    AI response:\\n    As a data scientist, my primary responsibility is to extract insights and knowledge from complex data sets. This involves using various tools and techniques to analyze patterns, relationships, and trends within the data.\\n\\nImagine you\\'re trying to understand your favorite sports team\\'s performance. You have a large dataset of statistics, such as game results, player stats, and attendance figures. My task is to use these datasets to identify patterns, correlations, and areas for improvement.\\n\\nI might start by asking questions like: \"What position does the quarterback play most often?\", \"Which players are the top scorers?\", or \"How many games has the team won in a row?\" Using this information, I can begin to create models and visualizations to help me understand the data better.\\n\\nMy ultimate goal is to provide actionable insights that can inform business decisions, drive growth, or solve real-world problems. For example, if I were working with a company producing energy products, I might use my findings to identify areas where they can optimize their production processes or improve customer satisfaction.'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"Rate the following explanation on a scale of 1 to 10 as a {job_title}: \n",
    "    AI response:\n",
    "    As a data scientist, my primary responsibility is to extract insights and knowledge from complex data sets. This involves using various tools and techniques to analyze patterns, relationships, and trends within the data.\n",
    "\n",
    "Imagine you're trying to understand your favorite sports team's performance. You have a large dataset of statistics, such as game results, player stats, and attendance figures. My task is to use these datasets to identify patterns, correlations, and areas for improvement.\n",
    "\n",
    "I might start by asking questions like: \"What position does the quarterback play most often?\", \"Which players are the top scorers?\", or \"How many games has the team won in a row?\" Using this information, I can begin to create models and visualizations to help me understand the data better.\n",
    "\n",
    "My ultimate goal is to provide actionable insights that can inform business decisions, drive growth, or solve real-world problems. For example, if I were working with a company producing energy products, I might use my findings to identify areas where they can optimize their production processes or improve customer satisfaction.\"\"\")\n",
    "\n",
    "\n",
    "messages = [system]\n",
    "template = ChatPromptTemplate(messages=messages)\n",
    "\n",
    "rater_chain = template | llm | StrOutputParser()\n",
    "rater_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  explainer: ChatPromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, template='You are a/an {job_title}, you are trying to help a human understand your work.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hello, I am trying to understand your work.'), additional_kwargs={})])\n",
       "             | ChatOllama(model='llama3.2:1b')\n",
       "             | StrOutputParser(),\n",
       "  rater: ChatPromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, template='Rate the following explanation on a scale of 1 to 10 as a {job_title}: \\n    AI response:\\n    As a data scientist, my primary responsibility is to extract insights and knowledge from complex data sets. This involves using various tools and techniques to analyze patterns, relationships, and trends within the data.\\n\\nImagine you\\'re trying to understand your favorite sports team\\'s performance. You have a large dataset of statistics, such as game results, player stats, and attendance figures. My task is to use these datasets to identify patterns, correlations, and areas for improvement.\\n\\nI might start by asking questions like: \"What position does the quarterback play most often?\", \"Which players are the top scorers?\", or \"How many games has the team won in a row?\" Using this information, I can begin to create models and visualizations to help me understand the data better.\\n\\nMy ultimate goal is to provide actionable insights that can inform business decisions, drive growth, or solve real-world problems. For example, if I were working with a company producing energy products, I might use my findings to identify areas where they can optimize their production processes or improve customer satisfaction.'), additional_kwargs={})])\n",
       "         | ChatOllama(model='llama3.2:1b')\n",
       "         | StrOutputParser()\n",
       "}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_chain = RunnableParallel(explainer=explainer_chain, rater=rater_chain)\n",
    "dependent_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"job_title\": \"Data Scientist\"\n",
    "}\n",
    "results = dependent_chain.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I would rate this explanation an 8 out of 10 as a Data Scientist.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "Strengths:\n",
      "\n",
      "* The explanation provides a clear understanding of the role and responsibilities of a data scientist.\n",
      "* It highlights the importance of using various tools and techniques to analyze complex data sets.\n",
      "* It offers specific examples of how a data scientist might use these skills in practice.\n",
      "\n",
      "Weaknesses:\n",
      "\n",
      "* The explanation could benefit from more technical detail. For example, it assumes that the reader is familiar with concepts like machine learning models, visualization tools, and statistical analysis.\n",
      "* Some of the language used is somewhat generic (e.g., \"create models\" and \"visualizations\") - data scientists often use more technical terms to describe their work.\n",
      "* There are no specific examples or anecdotes from the author's experience or other data scientists that illustrate their skills and expertise.\n",
      "\n",
      "To take this explanation to the next level, I would suggest adding more details about:\n",
      "\n",
      "* The specific tools and techniques used in practice (e.g., machine learning libraries, visualization software)\n",
      "* Real-world examples of how data science has been applied in industry\n",
      "* Case studies or success stories from other data scientists\n",
      "\n",
      "By doing so, you can make your explanation more engaging and informative for readers who are new to the field.\n"
     ]
    }
   ],
   "source": [
    "print(results[\"rater\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['rating'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['rating'], input_types={}, partial_variables={}, template='\\nIn one word classify the rating as either `positive` or `negative`.\\nGiven the following rating: {rating}\\n'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "In one word classify the rating as either `positive` or `negative`.\n",
    "Given the following rating: {rating}\n",
    "\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_template(prompt)\n",
    "chain = template | llm | StrOutputParser()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['rating'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['rating'], input_types={}, partial_variables={}, template='\\nYou are an expert in writing replay messages for positive ratings.\\nWrite a reply message for the following rating: {rating}\\n\\nAnswer:\\n'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_prompt = \"\"\"\n",
    "You are an expert in writing replay messages for positive ratings.\n",
    "Write a reply message for the following rating: {rating}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "positive_template = ChatPromptTemplate.from_template(positive_prompt)\n",
    "\n",
    "positive_chain = positive_template | llm | StrOutputParser()\n",
    "\n",
    "positive_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['rating'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['rating'], input_types={}, partial_variables={}, template='\\nYou are an expert in writing replay messages for negative ratings.\\nWrite a reply message for the following rating: {rating}\\n\\nAnswer:\\n'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_prompt = \"\"\"\n",
    "You are an expert in writing replay messages for negative ratings.\n",
    "Write a reply message for the following rating: {rating}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "negative_template = ChatPromptTemplate.from_template(negative_prompt)\n",
    "\n",
    "negative_chain = negative_template | llm | StrOutputParser()\n",
    "\n",
    "negative_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing_fn(inputs: dict[str, str]) -> RunnableParallel:\n",
    "    if \"positive\" in inputs[\"sentiment\"].lower():\n",
    "        print(\"Positive\")\n",
    "        return positive_chain\n",
    "    else:\n",
    "        print(\"Negative\")\n",
    "        return negative_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  sentiment: ChatPromptTemplate(input_variables=['rating'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['rating'], input_types={}, partial_variables={}, template='\\nIn one word classify the rating as either `positive` or `negative`.\\nGiven the following rating: {rating}\\n'), additional_kwargs={})])\n",
       "             | ChatOllama(model='llama3.2:1b')\n",
       "             | StrOutputParser(),\n",
       "  rating: RunnableLambda(lambda x: x['rating'])\n",
       "}\n",
       "| RunnableLambda(routing_fn)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "full_chain = {\"sentiment\": chain, \"rating\": lambda x:x[\"rating\"]} | RunnableLambda(routing_fn)\n",
    "\n",
    "full_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n",
      "Here's a potential reply message:\n",
      "\n",
      "\"I apologize that our response didn't meet your expectations. I'd be happy to try and reiterate the key points or provide additional context to help alleviate any confusion. Can you please let me know what specific aspects of the explanation were found to be boring, so I can tailor my next response accordingly?\"\n"
     ]
    }
   ],
   "source": [
    "response = full_chain.invoke({\"rating\": \"After reading the explanation, it was so boring.\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "\"I'm glad you found our explanation engaging! We're thrilled that you appreciated the effort we put into making learning about [Topic] as enjoyable as possible. Your kind words mean a lot to us!\"\n"
     ]
    }
   ],
   "source": [
    "response = full_chain.invoke({\"rating\": \"After reading the explanation, it was so interesting and informative.\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['concept1', 'concept2'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['concept1', 'concept2'], input_types={}, partial_variables={}, template='Explain these concepts: {concept1}, {concept2}.'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "def char_count_fn(response: str) -> int:\n",
    "    return len(response)\n",
    "\n",
    "def word_count_fn(response) -> int:\n",
    "    return len(response.split())\n",
    "\n",
    "template = ChatPromptTemplate.from_template(\n",
    "    \"Explain these concepts: {concept1}, {concept2}.\"\n",
    "    )\n",
    "\n",
    "chain = template | llm | StrOutputParser()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to explain these concepts.\n",
      "\n",
      "**Data Science**\n",
      "\n",
      "Data science is the practice of collecting, analyzing, and interpreting complex data to gain insights and make informed decisions. It involves using various techniques, tools, and technologies to extract knowledge from data, often in conjunction with domain expertise.\n",
      "\n",
      "Data scientists use statistical methods, machine learning algorithms, and other tools to:\n",
      "\n",
      "1. Collect and preprocess large datasets\n",
      "2. Analyze and visualize the data to identify patterns and trends\n",
      "3. Build predictive models to forecast outcomes or make predictions\n",
      "4. Evaluate the performance of these models using metrics such as accuracy, precision, and recall\n",
      "5. Communicate their findings and recommendations to stakeholders\n",
      "\n",
      "Data scientists often work in a variety of fields, including business, healthcare, finance, and social sciences. They may also collaborate with other teams, such as marketing, product development, or engineering.\n",
      "\n",
      "**Machine Learning**\n",
      "\n",
      "Machine learning is a subset of artificial intelligence (AI) that involves training algorithms on data to enable them to make predictions, classify objects, or make decisions without being explicitly programmed.\n",
      "\n",
      "There are several types of machine learning, including:\n",
      "\n",
      "1. Supervised learning: where the algorithm learns from labeled data and makes predictions based on that information\n",
      "2. Unsupervised learning: where the algorithm discovers patterns in unlabeled data\n",
      "3. Reinforcement learning: where the algorithm learns through trial and error\n",
      "\n",
      "Machine learning algorithms typically involve the following steps:\n",
      "\n",
      "1. Data preparation: gathering and preprocessing the data\n",
      "2. Model training: training a model using the labeled data\n",
      "3. Model evaluation: evaluating the performance of the model on new, unseen data\n",
      "4. Deployment: applying the trained model to new data or situations\n",
      "\n",
      "Common machine learning algorithms include:\n",
      "\n",
      "1. Linear regression\n",
      "2. Decision trees\n",
      "3. Neural networks\n",
      "4. Support vector machines (SVMs)\n",
      "5. Random forests\n",
      "\n",
      "Machine learning has a wide range of applications, including:\n",
      "\n",
      "1. Image recognition and classification\n",
      "2. Natural language processing (NLP) for text analysis and sentiment analysis\n",
      "3. Predictive maintenance in manufacturing\n",
      "4. Personalized recommendations on e-commerce platforms\n",
      "5. Autonomous vehicles and robotics\n",
      "\n",
      "**Key differences between Data Science and Machine Learning**\n",
      "\n",
      "While data science and machine learning are related fields, they have distinct focuses:\n",
      "\n",
      "* Data science is primarily concerned with extracting insights from data to inform decisions.\n",
      "* Machine learning is a specific technique for building models that can learn from data without being explicitly programmed.\n",
      "\n",
      "In other words, data science involves the broad concept of using data to make informed decisions, whereas machine learning is a specific methodology for achieving that goal.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"concept1\": \"Data Science\", \"concept2\": \"Machine Learning\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['concept1', 'concept2'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['concept1', 'concept2'], input_types={}, partial_variables={}, template='Explain these concepts: {concept1}, {concept2}.'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b')\n",
       "| StrOutputParser()\n",
       "| {\n",
       "    char_count: RunnableLambda(char_count_fn),\n",
       "    word_count: RunnableLambda(word_count_fn),\n",
       "    output: RunnablePassthrough()\n",
       "  }"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_runnable = (\n",
    "    template |\n",
    "    llm | \n",
    "    StrOutputParser() |\n",
    "    {\n",
    "        \"char_count\": RunnableLambda(char_count_fn),\n",
    "        \"word_count\": RunnableLambda(word_count_fn),\n",
    "        \"output\": RunnablePassthrough()\n",
    "    }\n",
    ")\n",
    "\n",
    "chain_runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_runnable.invoke({\"concept1\": \"Data Science\", \"concept2\": \"Machine Learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_count': 3251, 'word_count': 444, 'output': \"I'd be happy to explain data science and machine learning.\\n\\n**Data Science**\\n\\nData science is an interdisciplinary field that combines computer science, statistics, and domain-specific knowledge to extract insights and value from large datasets. It involves a systematic approach to identifying patterns, relationships, and trends in data to inform business decisions, scientific discoveries, or other applications.\\n\\nKey aspects of data science:\\n\\n1. **Data collection**: Gathering data from various sources, including databases, APIs, sensors, and users.\\n2. **Data preprocessing**: Cleaning, transforming, and preparing the data for analysis.\\n3. **Data analysis**: Using statistical techniques, machine learning algorithms, and visualization tools to identify patterns, trends, and insights.\\n4. **Model development**: Creating and evaluating models to predict outcomes or make predictions based on data.\\n5. **Model deployment**: Integrating models into business processes or applications.\\n\\nData science is an iterative process that involves:\\n\\n* Defining research questions and objectives\\n* Gathering and preprocessing data\\n* Analyzing data using various techniques\\n* Developing and validating models\\n* Deploying models in production\\n\\n**Machine Learning**\\n\\nMachine learning (ML) is a subset of artificial intelligence (AI) that involves training algorithms on large datasets to enable them to learn from experience and make predictions or decisions without being explicitly programmed.\\n\\nKey aspects of machine learning:\\n\\n1. **Data preparation**: Preparing the data for modeling by selecting, cleaning, and transforming it into a suitable format.\\n2. **Model development**: Training machine learning models using various algorithms, such as supervised, unsupervised, or reinforcement learning.\\n3. **Model evaluation**: Evaluating the performance of trained models using metrics such as accuracy, precision, recall, and F1 score.\\n4. **Hyperparameter tuning**: Fine-tuning model parameters to optimize performance.\\n\\nMachine learning is often used for:\\n\\n* Predictive modeling (e.g., forecasting sales or credit risk)\\n* Classification (e.g., spam vs. non-spam emails)\\n* Regression (e.g., predicting house prices or stock prices)\\n\\n**Key differences between Data Science and Machine Learning**\\n\\nWhile data science and machine learning are related fields, they have distinct focuses:\\n\\n1. **Data collection**: Data science involves gathering data from various sources, whereas machine learning is focused on extracting insights from existing data.\\n2. **Model development**: Data science typically involves developing models to make predictions or decisions, whereas machine learning algorithms can be used for a wide range of tasks beyond prediction.\\n3. **Purpose**: Data science aims to understand and explain the data, while machine learning is primarily focused on making predictions or decisions based on that understanding.\\n\\nIn summary, data science is an interdisciplinary field that combines computer science, statistics, and domain-specific knowledge to extract insights from data, whereas machine learning is a subset of AI that involves training algorithms on large datasets to enable them to make predictions or decisions without explicit programming.\"}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to explain data science and machine learning.\n",
      "\n",
      "**Data Science**\n",
      "\n",
      "Data science is an interdisciplinary field that combines computer science, statistics, and domain-specific knowledge to extract insights and value from large datasets. It involves a systematic approach to identifying patterns, relationships, and trends in data to inform business decisions, scientific discoveries, or other applications.\n",
      "\n",
      "Key aspects of data science:\n",
      "\n",
      "1. **Data collection**: Gathering data from various sources, including databases, APIs, sensors, and users.\n",
      "2. **Data preprocessing**: Cleaning, transforming, and preparing the data for analysis.\n",
      "3. **Data analysis**: Using statistical techniques, machine learning algorithms, and visualization tools to identify patterns, trends, and insights.\n",
      "4. **Model development**: Creating and evaluating models to predict outcomes or make predictions based on data.\n",
      "5. **Model deployment**: Integrating models into business processes or applications.\n",
      "\n",
      "Data science is an iterative process that involves:\n",
      "\n",
      "* Defining research questions and objectives\n",
      "* Gathering and preprocessing data\n",
      "* Analyzing data using various techniques\n",
      "* Developing and validating models\n",
      "* Deploying models in production\n",
      "\n",
      "**Machine Learning**\n",
      "\n",
      "Machine learning (ML) is a subset of artificial intelligence (AI) that involves training algorithms on large datasets to enable them to learn from experience and make predictions or decisions without being explicitly programmed.\n",
      "\n",
      "Key aspects of machine learning:\n",
      "\n",
      "1. **Data preparation**: Preparing the data for modeling by selecting, cleaning, and transforming it into a suitable format.\n",
      "2. **Model development**: Training machine learning models using various algorithms, such as supervised, unsupervised, or reinforcement learning.\n",
      "3. **Model evaluation**: Evaluating the performance of trained models using metrics such as accuracy, precision, recall, and F1 score.\n",
      "4. **Hyperparameter tuning**: Fine-tuning model parameters to optimize performance.\n",
      "\n",
      "Machine learning is often used for:\n",
      "\n",
      "* Predictive modeling (e.g., forecasting sales or credit risk)\n",
      "* Classification (e.g., spam vs. non-spam emails)\n",
      "* Regression (e.g., predicting house prices or stock prices)\n",
      "\n",
      "**Key differences between Data Science and Machine Learning**\n",
      "\n",
      "While data science and machine learning are related fields, they have distinct focuses:\n",
      "\n",
      "1. **Data collection**: Data science involves gathering data from various sources, whereas machine learning is focused on extracting insights from existing data.\n",
      "2. **Model development**: Data science typically involves developing models to make predictions or decisions, whereas machine learning algorithms can be used for a wide range of tasks beyond prediction.\n",
      "3. **Purpose**: Data science aims to understand and explain the data, while machine learning is primarily focused on making predictions or decisions based on that understanding.\n",
      "\n",
      "In summary, data science is an interdisciplinary field that combines computer science, statistics, and domain-specific knowledge to extract insights from data, whereas machine learning is a subset of AI that involves training algorithms on large datasets to enable them to make predictions or decisions without explicit programming.\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
